# -*- coding: utf-8 -*-
"""Poker_Hand_Prediction_Using_Random_Forests.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_Oc1rupEfSGamRITYftaZFXbaBIusy4T

# Predicting Poker Hand

### IMPORTING LIBRARIES
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd

import matplotlib.pyplot as plt

# %matplotlib inline

"""### LOADING THE DATASET"""

poker_df = pd.read_csv('/content/poker_hand_test.data')
poker_df

"""### ANALYSING AND PRE-PROCESSING THE DATA

### CHANGING NAMES OF COLUMN ACCORDING TO THE REFERENCES PROVIDED FROM WHERE THE DATASET IS OBTAINED
"""

poker_df.columns = ['first_suit', 'first_rank', 'second_suit', 'second_rank', 'third_suit', 'third_rank',
'fourth_suit', 'fourth_rank', 'fifth_suit', 'fifth_rank', 'hand']

labels = ['zilch', 'one_pair', 'two_pair', 'three_of_a_kind', 'straight', 'flush', 'full_house',
'four_of_a_kind', 'straight_flush', 'royal_flush']

poker_df

# SEPERATING THE DATASET INTO FEATURES (X) AND TARGET VALUES (y)
X = poker_df.iloc[:, 0:9]
y = poker_df.hand

"""### VISUALIZING WHETHER CLASS BALANCE IS PRESENT IN OUR DATASET OR NOT"""

import pandas as pd
from yellowbrick.classifier import ClassBalance
import matplotlib.pyplot as plt

# Assuming you have a DataFrame named poker_df
# Extract the target column (hand) from the DataFrame
y = poker_df['hand']

# Define the class labels
labels = ['zilch', 'one_pair', 'two_pair', 'three_of_a_kind', 'straight', 'flush', 'full_house',
          'four_of_a_kind', 'straight_flush', 'royal_flush']

# Create the ClassBalance visualizer with the specified labels
balance = ClassBalance(size=(1080, 720), labels=labels)

# Fit the visualizer with the target data (y)
balance.fit(y)

# Display the visualizer
balance.show()

"""##### THUS THERE IS CLASS IMBALANCE PRESENT IN OUR DATASET, ANS WE MUST REMOVE IT

### UP-SAMPLING FROM MINORITY CLASSES
"""

poker_df.loc[poker_df['hand']>=5, 'hand'] = 5

y = poker_df.hand

labels = ['zilch', 'one_pair', 'two_pair', 'three_of_a_kind', 'straight', 'flush_or_better']

balance = ClassBalance(size=(1080,720), labels=labels)

balance.fit(y)

balance.show()

"""### TRAINING THE RANDOM FORESTS CLASSIFIER"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5)

#CLF = SVC()
CLF = MLPClassifier(solver = 'adam', alpha = 0.05, hidden_layer_sizes=(50, 100, 50), learning_rate = 'adaptive', activation = 'tanh')

CLF.fit(X_train, y_train)

"""### EVALUATING THE MODEL"""

from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, precision_score

y_pred_test = CLF.predict(X_test)
y_pred_train = CLF.predict(X_train)

print ("Accuracy of the Model on Train Data is : {}".format(accuracy_score(y_train, y_pred_train)))
print ("Accuracy of the Model on Test Data is : {}".format(accuracy_score(y_test, y_pred_test)))

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
import numpy as np

# Function to plot the ROC curve
def plot_roc_curve(y_test, y_score, n_classes, class_labels):
    # Compute ROC curve and ROC area for each class
    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    # Plot all ROC curves
    plt.figure()
    colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
    for i, color in zip(range(n_classes), colors[:n_classes]):
        plt.plot(fpr[i], tpr[i], color=color, lw=2,
                 label=f'{class_labels[i]} (AUC = {roc_auc[i]:.2f})')

    # Plot the diagonal line
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic')
    plt.legend(loc='lower right')
    plt.show()

# Convert labels to binary format for multiclass problems
y_test_binarized = label_binarize(y_test, classes=np.unique(y_test))

# Predict scores on test data
y_score = CLF.predict_proba(X_test)

# Get number of classes
n_classes = len(np.unique(y_test))

# Define the class labels
class_labels = ['zilch', 'one_pair', 'two_pair', 'three_of_a_kind', 'straight', 'flush_or_better']

# Plot ROC curve
plot_roc_curve(y_test_binarized, y_score, n_classes, class_labels)

"""### CLASSIFICATION REPORT HEATMAP"""

from yellowbrick.classifier import ClassificationReport

report = ClassificationReport(CLF, size = (720, 640), classes = labels, cmap = 'PuBu')
report.score(X_test, y_test)
report.show()

"""### CLASS PREDICTION ERROR"""

error = ClassPredictionError(CLF, size= [1080, 720], classes = labels)
error.score(X_test, y_test)
error.poof()

"""# Save and Export the model for deployment"""

import joblib

# Assuming `CLF` is your trained model
# Specify the file path where you want to save the model
model_file_path = 'trained_model.joblib'

# Save the trained model to the specified file path
joblib.dump(CLF, model_file_path)

print(f"Model saved to {model_file_path}")